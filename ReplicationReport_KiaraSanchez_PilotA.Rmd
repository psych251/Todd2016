---
title: "Replication of Does Seeing Faces of Young Black Boys Facilitate the Identification of Threatening Stimuli? by Todd et al. (2016, Psychological Science)"
author: "Kiara Sanchez (klsanch@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

##Introduction

Implicit bias and social cognition research demonstrates strong cognitive biases linking Black men to threat, crime, and violence (Correll, et al., 2002; Trawalter et al., 2008; Amodio, 2014; Eberhardt et al., 2004). Through object categorization tasks, the current paper found that these stereotypes extend to Black boys. We attempted to replicate Experiment 3, which used photos of both Black boys and men, and "threatening" and "safe" words. We attempted to replicate the following result: 

"Analyses of error-rate data revealed that...there was a significant Race of Prime × Target Word interaction, F(1, 61) = 32.30, p < .001, ηp2 = .35." 

Link to experiment: http://stanford.edu/~klsanch/Todd2016Replication_KS.html 

##Methods


###Power Analysis

Original $\sf{η_{p}}$^2^ = .35 which translates into an effect size of 0.73 via g*Power software. Power analyses shows that I need 8 participants for 95% power. This effect size is for the 2 (race of prime: Black, White) × 2 (target word: threatening, safe) repeated measures analysis of variance (ANOVA).


###Planned Sample
I proposed a sample of 20 (2.5 times the sample size needed) because I will exclude non-White participants. The original sample consisted of White students, and it is unclear how White participants were recruited. I determined that inclusive recruitment and post hoc exclusion of non-White participants was an approporiate method in order to avoid self-selection bias based on race demographics. See below for other exclusion criteria from original paper: 

"We excluded data from 16 participants with below- chance accuracy on the sequential priming task; retaining their data did not meaningfully alter the results, except that the Race of Prime × Target Word interaction was no longer significant for RTs (p = .116); all other significant effects remained significant (ps < .01). We also excluded data from 2 participants who pressed the same response key on every trial. Computer malfunctions resulted in substantial data loss for 2 additional participants. Together, these exclusions left a final sample of 62 (32 women, 30 men)."

###Materials & Procedure
"The sequential priming task that we used (adapted from Cesario, Plaks, Hagiwara, Navarrete, & Higgins, 2010) was very similar to that used in Experiment 2b, with these exceptions: First, we replaced the gun and tool images with word stimuli. The participants’ task was to ignore the prime images and instead to rapidly and accurately categorize the words as threatening (violent, dangerous, hostile, aggressive, criminal, and threatening) or safe (innocent, harmless, friendly, trustworthy, peace- ful, and safe). Second, we increased the response deadline to 750 ms. Each of the 24 face primes was paired with each of the 12 target words, which resulted in 288 randomly ordered experimental trials that appeared in a single block of trials. Eight practice trials preceded the experimental trials."

####Experiment 1 & 2b procedure: 
"Participants completed a categorization task in which two images flashed on the monitor in quick succession. Participants were instructed to ignore the first image (the prime), which was always a face; it merely signaled that the second image was about to appear. Instead, their pri- mary task was to quickly and accurately categorize the second image (the target object) as a gun or a toy by pressing one of two response keys (key assignments were counterbalanced across participants).
The primes were 12 photos of boys (6 Black, 6 White) taken from the Child Affective Facial Expression set (LoBue & Thrasher, 2015). We selected these photos using the following criteria: The faces had to be easily categorized by race, to have a neutral expression, to have no idiosyncrasies (e.g., facial scars), and to be similar in actual age (mean age for Black faces = 4.98 years; mean age for White faces = 5.01 years; p > .250). Each photo was cropped so that it included only the head and was standardized in size. The target objects were 6 gun images taken from Payne (2001) and 6 toy images (e.g., a rattle) taken from online sources. The toy images were con- verted to gray scale and sized to match the gun images.
Each trial sequence began with a blank screen (500 ms), followed by a face prime (200 ms), then a tar- get object (200 ms), and finally a pattern mask (which remained on screen until participants responded). If par- ticipants did not respond within 500 ms, a message (“Please respond faster!”) appeared for 1 s. Each of the 12 face primes was paired once with each of the 12 target objects, which resulted in 144 randomly ordered experi- mental trials. Eight practice trials preceded the experimental trials.

The weapon identification tasks used in Experiments 2a and 2b were very similar to that used Experiment 1, with the following exceptions: First, along with the pho- tos of boys, we included 12 photos of men (6 Black, 6 White) taken from the Chicago Face Database (Ma, Correll, & Wittenbrink, 2015). We selected these photos using criteria similar to those used to select the child photos in Experiment 1. Second, we replaced the toy images with 6 images of tools taken from Payne (2001). Each of the 24 face primes was paired once with each of the 12 target objects, which resulted in 288 randomly ordered experi- mental trials. Sixteen practice trials preceded the experi- mental trials. In Experiment 2a, the adult and child primes appeared in separate, counterbalanced blocks of trials. In Experiment 2b, the adult and child primes appeared together in a single block of trials."

###Analysis Plan

Key analysis is a 2 (race of prime: White, Black) x 2 (target word: safe, threatening) within-subjects repeated measures ANOVA.

**The key result is a Race of Prime × Target Word interaction: F(1, 61) = 32.30, p < .001, ηp2 = .35. **

See "Planned Sample" section for exclusion criteria.


###Differences from Original Study

The original study sample consisted of White undergraduate college students. We recruited adult participants through MTurk and excluded non-White participants. We do not anticipate significant differences in results based on these criteria.


### Data preparation

```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions
library(tidyverse)
library(rjson)
library(ez)
library(forcats)
library(plyr)
library(dplyr)
install.packages('TMB')
library(sjstats)

####Import data
path <- "/Users/kiarasanchez/Desktop/251/Todd2016/production-results/"

files <- dir(path, pattern = "*.json")

#files <- dir(paste0(path,"sandbox-results/"), 
             #pattern = "*.json")
d.raw <- data.frame()

for (f in files) {
  jf <- paste0(path,f)
  jd <- fromJSON(file=jf)

#for (f in files) {
 # jf <- paste0(path, f)
#  jd <- fromJSON(paste(readLines(jf), collapse=""))
  

  id <- data.frame(workerid = jd$WorkerId, 
                   religAff = jd$answers$demographicsData[[1]]$ReligiousAffiliation,
                   religAtt = jd$answers$demographicsData[[1]]$ReligiousAttendance,
                   ses = jd$answers$demographicsData[[1]]$SES,
                   age = jd$answers$demographicsData[[1]]$Age,
#                   political = jd$answers$demographicsData[[1]]$Political,
                   comments = jd$answers$demographicsData[[1]]$Comments,
                   Edu = jd$answers$demographicsData[[1]]$Education,
                   Citizen = jd$answers$demographicsData[[1]]$Citizen,
                   Gender = jd$answers$demographicsData[[1]]$Male,
                   Ethnicity = jd$answers$demographicsData[[1]]$Ethnicity,
                   trial_num = 1:288,
                   rt = NA,
                   correct = NA,
                   raceStim = NA,
                   word= NA,
                   race = NA,
                   wordStim = NA,
                   responded = NA)

for(i in 1:144) {
    id$rt[id$trial_num == i] <- jd$answers$data[[i]]$rt
    id$raceStim[id$trial_num == i] <- jd$answers$data[[i]]$raceStim
    id$word[id$trial_num == i] <- jd$answers$data[[i]]$word
    id$race[id$trial_num == i] <- jd$answers$data[[i]]$race
    id$wordStim[id$trial_num == i] <- jd$answers$data[[i]]$wordStim
    id$responded[id$trial_num == i] <- jd$answers$data[[i]]$responded
    id$correct[id$trial_num == i] <- jd$answers$data[[i]]$correct
  }
  
    d.raw <- bind_rows(d.raw, id)
    
}


summary(d.raw)

#fix race 
d <- d.raw %>%
  select(-race) %>%
  mutate(targetRace = substr(d.raw$raceStim,0,1))

#identify NAs
d$rt[d$rt == 0] <- NA

d$word = factor(d$word) 
d$targetRace = factor(d$targetRace)
d$Edu = factor(d$Edu) 
d$Citizen = factor(d$Citizen)
d$Gender = factor(d$Gender)
d$Ethnicity = factor(d$Ethnicity)

###Factoring and re-labeling

d$word = fct_recode(d$wordStim,
                      "Safe" = "innocent",
                      "Threatening" = "violent",
                      "Safe" = "harmless",
                      "Safe" = "friendly",
                      "Safe" = "trustworthy",
                      "Safe" = "peaceful",
                      "Safe" = "safe",
                      "Threatening" = "dangerous", 
                      "Threatening" = "hostile",
                      "Threatening" = "aggressive",
                      "Threatening" = "criminal",
                      "Threatening" = "threatening"
                      )

d$targetRace = fct_recode(d$targetRace,
                      "Black" = "b",
                        "White" = "w")

d$Gender = fct_recode(d$Gender,
                   "Male" = "1",
                   "Female" = "0")
                   
d$Ethnicity = fct_recode(d$Ethnicity,
                    "Caucasian/White" = "1",
                    "Hispanic/Latino/Latina" = "2",
                    "African American/Black" = "3",
                    "Hispanic/Latino/Latina" = "4",
                    "East Asian" = "5",
                    "Middle Eastern" = "6",
                    "Pacific Islander" = "7",
                    "Native American" = "8",
                    "Mixed" = "9")

# Number of participants
length(unique(d$workerid))

#### Prepare data for analysis - create columns etc.

#create targetAge variable 
  # levels: child, adult
  # 01-06 = child, 07-12 = adult
#d$targetAge = fct_recode(d$raceStim,
                   # "child" = ends_with(01),
                   # "adult" = ends_with(07))

####Exclusion 

#non-white 
d <- d %>%
  filter(Ethnicity == "Caucasian/White")

length(unique(d$workerid))

#participants with below 50% accuracy 
assess_accuracy  <- d %>%
  filter(responded==1) %>%
  group_by(workerid) #%>%
  summarise(mean_accuracy = mean(accuracy))# %>%
  filter(mean_accuracy < 0.5)

#exclude participants with below 50% accuracy
d = d %>%
  filter(workerid != "assess_accuracy IDs")

#summarize error rate

  #reverse code accuracy in order to calculate % error 
    # new variable = 'error', levels: 1 = incorrect, 0 = correct 
#d$error = fct_recode(d$correct,
                   # 1 = 0,
                   # 0 = 1)

#error <- d %>%
  #filter(responded==1) %>%
  #group_by(targetRace, workerid) %>%
#summarise(error_rate = mean(error))

#exclude responded == 0
d = d %>%
  filter(responded == 1)

#print head 

#print(head(d))

#prepare data for plotting
  #this code is set up to output a graph for the interaction of time (pre and post) and condition (waitlist and class) on the dependent variable (YVAR) of your choice. To use just replace 'YVAR' with the name of your variable of interest. You should replace it 3 times. 

dv <- ddply(d, .(targetRace,word), summarise, accuracy = mean(accuracy, na.rm=TRUE)) #calculate mean Ys
dvsd = ddply(d, .(targetRace,word), summarise, sdY = sd(accuracy,na.rm=TRUE)) #calculate sd
dvl = ddply(d, .(targetRace,word), summarise, lY = length(accuracy)) #calculate 'n'
dv$sdY = dvsd$sdY #add sd to dataframe
dv$lY = dvl$lY #add N to dataframe
dv$seY = dv$sdY/sqrt(dv$lY) #calculate standard error
dv$upper = dv$accuracy + dv$seY #calculate +1 se interval upper limit
dv$lower = dv$accuracy - dv$seY #calculate -1 se intervale lower limit
#dv = dv[c(-3,-6),]

#dv$word = factor(dv$word, labels = c("Safe","Threatening")) #Make sure X1 is a factor with interpretable labels
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

```{r}
# 2 x 2 anova

t1 <- aov(accuracy ~ targetRace * word, data=d)
summary(t1)

#calculate replication error
#t1_error = compareValues(reportedValue = , obtainedValue = )
#t1_error 

# calculate eta squared 
etaSQ_t1 = eta_sq(t1)
#etaSQ_t1 

#calculate replication error
#t1etaSQ_error = compareValues(reportedValue = , obtainedValue = )
#t1etaSQ_error 
```

```{r}
dodge <- position_dodge(width=0.8) 
plot = ggplot(dv, aes(x = word, y = accuracy)) +
  geom_bar(stat="identity", width = .8, aes(fill=targetRace),position = "dodge") +
  scale_fill_brewer(palette="Set1")  + #change colors of the bars
  scale_y_continuous(limits=c(0,1)) + #this changes the Y axis, make sure to include 0
  theme(axis.text.y = element_text(face="italic",size = rel(1.5),angle=90, hjust=1, vjust=.5)) + #changes y axis text
  theme(axis.title.y=element_text(size=rel(1.5))) + #changes y axis text
  theme_bw()+ #gives it a nice clean theme (purely aesthetic)
  geom_errorbar(aes(ymax=upper, ymin=lower, fill= targetRace),width=.25, position = dodge) #+ #adds error bars!
  #theme(panel.background = element_rect(fill="white",colour="white", size = rel(2)))+theme(panel.border = element_blank()) #more aesthetic changes

```

```{r}
print(plot)
```

